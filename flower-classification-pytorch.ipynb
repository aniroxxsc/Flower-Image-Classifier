{"cells":[{"metadata":{},"cell_type":"markdown","source":"This project is has some objective\n* Build a custom model\n*\tUse different pretrained models(alexnet, vgg16,resnet18, resnet36)\n*\tUse different optimization algorithm(sgd,sgd with momentum,adam)\n*\tUse different learning rate.\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch import nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cuda helps in utilizing the GPU for faster computation\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu' )\ndevice","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will import the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"Imagesize = (64,64)\ntransform = transforms.Compose([transforms.ToTensor(),\n                                transforms.Resize(Imagesize),\n                                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n                                ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = torchvision.datasets.ImageFolder(root='../input/flowers-recognition/flowers/flowers',transform = transform)\ndataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"dataset has the following classes \",dataset.classes)\nprint(type(dataset))\nnum_classes = len(dataset.classes)\nprint(num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now splitting data in trainset and testset\ntrainset, testset = torch.utils.data.random_split(dataset, [3900,423])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* num_workers, which denotes the number of processes that generate batches in parallel. A high enough number of workers assures that CPU computations are efficiently managed, i.e. that the bottleneck is indeed the neural network's forward and backward operations on the GPU (and not data generation)."},{"metadata":{"trusted":true},"cell_type":"code","source":"trainloader = torch.utils.data.DataLoader(dataset=trainset, batch_size=16,num_workers=3, shuffle=True) \ntestloader = torch.utils.data.DataLoader(dataset=testset, batch_size=16,num_workers=3, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building Neural Network Architecture**"},{"metadata":{},"cell_type":"markdown","source":"* **Convnet Architecture - (((((Conv+Relu)*n)+pool)*m) + F.C.)**\n* **Image size after convolution - ((W-F+2P)/S) + 1**\n* **Conv2d outputs a tensor of shape [batch_size, n_features_conv, height, width]**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ConvNet(nn.Module):\n    def __init__(self,num_classes=5):\n        super(ConvNet,self).__init__()\n        self.layer1 = nn.Sequential(\n                    nn.Conv2d(3,16, kernel_size=3, stride=1, padding=1),\n                    nn.BatchNorm2d(16),\n                    nn.ReLU(),\n        )           #output - 16*64*64 image\n        \n        self.layer2 = nn.Sequential(\n                    nn.Conv2d(16,32, kernel_size=3, stride=1, padding=1),\n                    nn.BatchNorm2d(32),\n                    nn.ReLU(),\n                    #output - 32*64*64\n                    nn.MaxPool2d(kernel_size=2, stride=2)\n                    #output - 32*32*32\n        )           \n        \n        self.layer3 = nn.Sequential(\n                    nn.Conv2d(32,64, kernel_size=3, stride=1, padding=1),\n                    nn.BatchNorm2d(64),\n                    nn.ReLU(),\n                    #output - 64*32*32\n        )\n        self.layer4 = nn.Sequential(\n                    nn.Conv2d(64,128, kernel_size=5, stride=1, padding=2),\n                    nn.BatchNorm2d(128),\n                    nn.ReLU(),\n                    #output - 128*32*32\n                    nn.MaxPool2d(kernel_size=2, stride=2)\n                    #output - 128*16*16\n        )\n        self.fc1 = nn.Linear(128*16*16, 128)\n        self.fc2 = nn.Linear(128, 16)\n        self.fc3 = nn.Linear(16, num_classes)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = out.reshape(out.size(0), -1)\n        out = self.fc1(out)\n        out = self.fc2(out)\n        out = self.fc3(out)\n        return F.log_softmax(out,dim=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ConvNet(num_classes).to(device)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TrainLoss = []\nTrainAcc = []\nTestLoss = []\nTestAcc = []\nnum_epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(TrainLoss,TrainAcc, TestLoss, TestAcc, num_epochs, model, trainloader, testloader, criterion, optimizer):\n    total_step = len(trainloader)\n    for epoch in range(num_epochs):\n        trainAcc = 0\n        testAcc = 0\n        for i, data in enumerate(trainloader,0):\n            images, labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            trainLoss = criterion(outputs, labels)\n            optimizer.zero_grad()                                        \n            trainLoss.backward()                                        \n            optimizer.step()  \n            preds = outputs.data.max(dim=1,keepdim=True)[1]\n            trainAcc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n        trainAcc = trainAcc/len(trainloader.dataset) * 100\n        \n        # For testset\n        for i, data in enumerate(testloader):\n            model.eval()\n            images, labels = data\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            testLoss = criterion(outputs, labels)\n            preds = outputs.data.max(dim=1,keepdim=True)[1]\n            testAcc += preds.eq(labels.data.view_as(preds)).cpu().sum()\n        testAcc = testAcc/len(testloader.dataset) * 100\n        print(\"Epoch {} =>  loss : {trainLoss:.2f};   Accuracy : {trainAcc:.2f}%;   test_loss : {testLoss:.2f};   test_Accuracy : {testAcc:.2f}%\".format(epoch+1, trainLoss=trainLoss.item(), trainAcc=trainAcc, testLoss=testLoss.item(), testAcc=testAcc))\n        TrainLoss.append(trainLoss)\n        TrainAcc.append(trainAcc)\n        TestLoss.append(testLoss)\n        TestAcc.append(testAcc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(TrainLoss,TrainAcc, TestLoss, TestAcc, num_epochs, model, trainloader, testloader, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With other optimizers --SGD"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_sgd = ConvNet(num_classes).to(device)\nmodel_sgd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model_sgd.parameters(), lr=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(TrainLoss,TrainAcc, TestLoss, TestAcc, num_epochs, model_sgd, trainloader, testloader, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With other Optimizer (SGD With Momentum)"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_sgd_momentum = ConvNet(num_classes).to(device)\nmodel_sgd_momentum","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model_sgd_momentum.parameters(), lr=0.01, momentum=0.9)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(TrainLoss,TrainAcc, TestLoss, TestAcc, num_epochs, model_sgd_momentum, trainloader, testloader, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"using AlexNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"alexnet = torchvision.models.alexnet(pretrained=True)\nalexnet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alexnet.classifier[6].out_features = 5\nfor param in alexnet.features.parameters(): \n    param.requires_grad = False\n\nalexnet = alexnet.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(alexnet.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(TrainLoss,TrainAcc, TestLoss, TestAcc, num_epochs, alexnet, trainloader, testloader, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"using VGG16"},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg = torchvision.models.vgg16(pretrained=True)\nvgg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg.classifier[6].out_features = 5\nfor param in vgg.features.parameters(): \n    param.requires_grad = False\n\nvgg = vgg.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(vgg.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnum_epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(TrainLoss,TrainAcc, TestLoss, TestAcc, num_epochs, vgg, trainloader, testloader, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using Resnet18"},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet18 = torchvision.models.resnet18(pretrained= True)\nresnet18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fr = resnet18.fc.in_features\nresnet18.fc = nn.Linear(fr, 5)\n\nresnet18 = resnet18.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nnum_epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(TrainLoss,TrainAcc, TestLoss, TestAcc, num_epochs, resnet18, trainloader, testloader, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Resnet34"},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet34 = torchvision.models.resnet34(pretrained=True)\nresnet34","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet34","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fr = resnet34.fc.in_features\nresnet34.fc = nn.Linear(fr, 5)\nresnet34 = resnet34.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss and optimizer\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(resnet34.parameters(), lr=0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(TrainLoss,TrainAcc, TestLoss, TestAcc, num_epochs, resnet34, trainloader, testloader, criterion, optimizer)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}